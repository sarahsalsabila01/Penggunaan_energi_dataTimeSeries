# -*- coding: utf-8 -*-
"""TS_Sarah2.2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1J1zJtNkVlT1qzTImTD638tS6d1u8tlO9

<h1><center>Profil Dicoding</center></h1><hr>
<p> Nama  : Sarah Salsabila </p>
<p> Email : m314v4331@dicoding.org</p>
<p> Alamat: Karawang , Jawabarat</p>
"""

#Ambil data dari gdrive
from google.colab import drive
drive.mount('/content/drive')

#membaca data
import pandas as pd
df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/dataset/Energy.csv')

df.head()

df.shape

df.isnull().sum()

df.dtypes

import numpy as np
from keras.layers import Dense, LSTM
import matplotlib.pyplot as plt
import tensorflow as tf

#mengubah dtype menjadi date
df['DATE'] = pd.to_datetime(df['DATE'])
df.head()

df.columns

#menghapus kolom
df = df.drop(columns=['TYPE', 'START TIME', 'END TIME', 'UNITS', 'COST',
       'NOTES'])
df.head()

#mengatur agar diurutkan berdasarkan date , agar terurut
df.sort_values(by='DATE')

#mencari nilai tertinggi dari data tegangan
max = df['USAGE'].max()
print('Max Value : ', max)

#mencari nilai terendah dari data tegangan
min = df['USAGE'].min()
print('Min Value : ', min)

#menghitung batas <10% maenya dari data
batas_mae =(max - min)*(10/100)
batas_mae

#mengecek apakah ada data null
df.isnull().sum()

#membuat plot data berdasarkan date dan tegangan
import matplotlib.pyplot as plt
date  = df['DATE'].values
power  = df['USAGE'].values
 
 
plt.figure(figsize=(15,5))
plt.plot(date,power)
plt.title('power yang digunakan',
          fontsize=20);

#membagi validasi data 20%
from sklearn.model_selection import train_test_split

power_train, power_test, date_train, date_test = train_test_split(power, date, test_size = 0.2, random_state = 0 , shuffle=False)
print(len(power_train), len(power_test))

def windowed_dataset(series, window_size, batch_size, shuffle_buffer):
    series = tf.expand_dims(series, axis=-1)
    ds = tf.data.Dataset.from_tensor_slices(series)
    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)
    ds = ds.flat_map(lambda w: w.batch(window_size + 1))
    ds = ds.shuffle(shuffle_buffer)
    ds = ds.map(lambda w: (w[:-1], w[-1:]))
    return ds.batch(batch_size).prefetch(1)

data_power_train = windowed_dataset(power_train, window_size=60, batch_size=100, shuffle_buffer=5000)
data_power_test = windowed_dataset(power_test, window_size=60, batch_size=100, shuffle_buffer=5000)

model = tf.keras.models.Sequential([
  tf.keras.layers.LSTM(60, return_sequences=True),
  tf.keras.layers.LSTM(60),
  tf.keras.layers.Dense(30, activation="relu"),
  tf.keras.layers.Dense(10, activation="relu"),
  tf.keras.layers.Dense(1),
])

#membuat callback 
class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('mae')is not None and logs.get('mae') <= batas_mae):
      print("\n Mae nya sudah dibawah ", batas_mae , ", training data dihentikan !")
      self.model.stop_training = True

callbacks = myCallback()

#optimizer dan menggunakan learning rate
optimizer = tf.keras.optimizers.SGD(lr=1.0000e-04, momentum=0.9)
model.compile(loss=tf.keras.losses.Huber(),
              optimizer=optimizer,
              metrics=["mae"])

#melakukan model fit .
#tidak menyertakan callback agar sesuai dengan review notes . harus mencapai nilai terbaik untuk pendekatan kekasus yang lebih baik
history = model.fit(data_power_train,
                    epochs=30,
                    validation_data=data_power_test)

# plot dari maenya
import matplotlib.pyplot as plt
plt.plot(history.history['mae'])
plt.plot(history.history['val_mae'])
plt.title('MAE')
plt.ylabel('mae')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# plot dari lossnya
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()